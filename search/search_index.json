{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>Welcome to our website.</p>"},{"location":"checklist/","title":"Site Checklist","text":"<ol> <li>Customize the fields in your mkdocs.yml file</li> <li>Configure Google Analytics to use the right site ID</li> <li>Make sure that your .gitignore file includes the <code>site</code> directory</li> <li>Test the build</li> <li>Make sure the Edit button appears</li> <li>Make sure that code color heightening renders correctly</li> <li>run <code>git config advice.addIgnoredFile false</code></li> </ol>"},{"location":"code-highlight-test/","title":"Code Syntax Color Highlight Test","text":""},{"location":"code-highlight-test/#python","title":"Python","text":"<pre><code>hello_string = \"Hello World!\"\nprint(hello_string)\nx = 1\nif x == 1:\n    # indented four spaces\n    print(\"x is 1.\")\n</code></pre>"},{"location":"contact/","title":"Contact","text":"<p>Please contact me on LinkedIn</p> <p>Thanks! - Dan</p>"},{"location":"course-description/","title":"Introduction to Graph Databases","text":"<p>Credits: 3 Length: 14 Weeks Level: Undergraduate (Junior/Senior) or Graduate Introductory Level Prerequisites:</p> <ul> <li>Prior coursework in databases or data modeling (recommended)</li> <li>Basic programming knowledge (Python, JavaScript, or similar)</li> <li>Familiarity with data structures (arrays, hash maps, trees)</li> </ul>"},{"location":"course-description/#course-overview","title":"Course Overview","text":"<p>This course introduces students to graph databases as powerful tools for representing, querying, and analyzing highly connected information. Students learn why traditional relational databases struggle with modern, relationship-heavy data and how Labeled Property Graph (LPG) databases treat relationships as first-class citizens with attributes, directionality, and semantics.</p> <p>We begin by contrasting the architectural foundations of RDBMS vs. NoSQL systems, explore the design motivations behind graph data models, and introduce the formal elements of LPGs: nodes, edges, properties, labels, and schema options. Students then gain hands-on experience modeling and querying real-world graphs using languages such as openCypher, GSQL, or Gremlin (depending on instructor preference).</p> <p>The course emphasizes building real applications: social networks, recommendation engines, fraud detection pipelines, supply-chain models, knowledge graphs, bill-of-materials (BOM), and healthcare data modeling. Students practice evaluating when to choose graph data models, how to optimize them, how to measure performance, and how to design graph schemas aligned with real business domains.</p> <p>The capstone project involves building an end-to-end graph application using an LPG graph database.</p>"},{"location":"course-description/#sample-outline-14-weeks","title":"Sample Outline (14 Weeks)","text":""},{"location":"course-description/#week-1-introduction-to-graph-thinking","title":"Week 1 \u2013 Introduction to Graph Thinking","text":"<ul> <li>Why data modeling matters in our AI-driven world</li> <li>The importance of world-models</li> <li>Six major representations of data</li> <li>RDBMS vs. OLAP vs. NoSQL</li> <li>When graphs outperform tables</li> <li>Edges are a first class citizen</li> <li>LPG: The most maintainable information model</li> <li>Case Study: Neo4j</li> <li>Timeline of Graph Database</li> </ul>"},{"location":"course-description/#week-2-nosql-and-the-rise-of-graphs","title":"Week 2 \u2013 NoSQL and the Rise of Graphs","text":"<ul> <li>Key-value, document, wide-column, and graph stores</li> <li>Tradeoff analysis (model precision, flexibility, scaling)</li> <li>Representations of knowledge</li> <li>The Knowledge Triangle</li> <li>Single server graphs</li> <li>Distributed graphs</li> <li>Case Study: TigerGraph</li> </ul>"},{"location":"course-description/#week-3-labeled-property-graph-lpg-information-model","title":"Week 3 \u2013 Labeled Property Graph (LPG) Information Model","text":"<ul> <li>Nodes, edges, labels, properties</li> <li>Representing metadata</li> <li>Open vs. Closed World Models</li> <li>Schema-optional vs. schema-enforced modeling</li> <li>Tools to view graph data models</li> <li>Adding rules to graphs</li> <li>Validating documents</li> <li>Validating graphs</li> </ul>"},{"location":"course-description/#week-4-query-languages-for-graphs","title":"Week 4 \u2013 Query Languages for Graphs","text":"<ul> <li>openCypher</li> <li>GSQL / Gremlin overview</li> <li>Path patterns, hops, aggregations</li> <li>GQL - the emerging standard for advanced query languages</li> </ul>"},{"location":"course-description/#week-5-index-free-adjacency-performance","title":"Week 5 \u2013 Index-Free Adjacency &amp; Performance","text":"<ul> <li>Traversal fundamentals</li> <li>Constant-time neighbor access</li> <li>Cost comparison: joins vs. traversals</li> <li>MicroSim: Chart: Comparing Multi-hop performance on RDBMS vs. Graph </li> </ul>"},{"location":"course-description/#week-6-benchmarking-techniques","title":"Week 6 \u2013 Benchmarking Techniques","text":"<ul> <li>Why benchmarking is critical to promoting graphs</li> <li>Predicting the future value of insights</li> <li>LDBC SNB benchmark</li> <li>Measuring graph performance</li> <li>Query latency, throughput, and scalability</li> </ul>"},{"location":"course-description/#week-7-modeling-social-networks-and-language","title":"Week 7 \u2013 Modeling Social Networks and Language","text":"<ul> <li>Friend graphs</li> <li>Modeling human resources</li> <li>Case Study: The Org Chart and Skill Management</li> <li>Diagram: Org Chart Models</li> <li>Influence graphs</li> <li>Modeling with edges as first-class citizens</li> <li>Extending your model</li> <li>Adding discussions</li> <li>Adding natural language language processing</li> <li>Adding products to your graph</li> <li>Adding sentiment to your graph</li> <li>Detecting bad fake accounts</li> <li>Case Study: Assigning Tasks from the Backlog</li> </ul>"},{"location":"course-description/#week-8-knowledge-representation-with-concept-graphs","title":"Week 8 \u2013 Knowledge Representation with Concept Graphs**","text":"<ul> <li>Concept dependency graphs</li> <li>Curriculum graphs</li> <li>Ontology-connected graph structures</li> <li>The Simple Knowledge Organization System (SKOS)</li> <li>Preferred Labels and Alternate Labels</li> <li>The Acronym List</li> <li>The Glossary</li> <li>The Controlled Vocabulary</li> <li>The Taxonomy</li> <li>The Ontology</li> </ul>"},{"location":"course-description/#week-9-graph-algorithms","title":"Week 9 - Graph Algorithms","text":"<ul> <li>Search</li> <li>Breath First Search (BFS)</li> <li>Depth First Search (DFS)</li> <li>A-Star (A*)</li> <li>Pathfinding</li> <li>Traveling Salesman</li> <li>PageRank</li> <li>Community detection</li> <li>Graph Neural Networks</li> </ul>"},{"location":"course-description/#week-9-graph-modeling-patterns","title":"Week 9 \u2013 Graph Modeling Patterns**","text":"<ul> <li>Subgraphs</li> <li>Supernode vs. anti-pattern nodes</li> <li>Hyperedges, multi-edges</li> <li>Time-based modeling patterns</li> <li>Time Trees</li> <li>Modeling Internet of Things Events</li> <li>Modeling Rules and Decision Trees</li> <li>Bitemporal Graph Models (Advanced Topic)</li> </ul>"},{"location":"course-description/#weeks-10-and-11-industry-reference-data-models-part-i","title":"Weeks 10 and 11 \u2013 Industry Reference Data Models (Part I)**","text":"<ul> <li>Web storefront graph model</li> <li>Product catalogs</li> <li>Bill-of-Materials (BOM) and complex parts</li> <li>Supply chain modeling</li> <li>Modeling financial transactions</li> <li>Fraud detection graphs</li> <li>Highly Regulated Industries</li> <li>Anti-Money Laundering (AML)</li> <li>Know Your Customer (KYC)</li> <li>Account-network traversal</li> <li>Provider/patient graphs</li> <li>Electronic health record modeling</li> <li>IT asset and dependency graphs</li> <li>Graph analytics vs. transactional graph queries</li> <li>Graph embeddings (introduction)</li> </ul>"},{"location":"course-description/#weeks-12-13-and-14-capstone-project-presentations","title":"Weeks 12, 13 and 14 \u2013 Capstone Project Presentations**","text":"<ul> <li>Students present a full graph application</li> <li>Modeling choices, data loading, queries, and performance measurements</li> </ul>"},{"location":"course-description/#sample-of-concepts-covered","title":"Sample of Concepts Covered**","text":"<ul> <li>NoSQL Databases</li> <li>Six Representations of Data</li> <li>RDBMS vs. Graph Databases</li> <li>OLAP vs. OLTP Workloads</li> <li>Key-Value Stores</li> <li>Document Databases</li> <li>Graph Stores</li> <li>Tradeoff Analysis / CAP</li> <li>Representations of Knowledge</li> <li>Concept Graphs</li> <li>Index-Free Adjacency</li> <li>Performance &amp; Benchmarking</li> <li>Web Storefront Modeling</li> <li>Learning Management System Modeling</li> <li>Curriculum &amp; Course Dependency Graphs</li> <li>Healthcare Data Graphs</li> <li>IT Asset &amp; Dependency Graphs</li> <li>Financial Transaction Graphs</li> <li>Fraud Detection Graphs</li> <li>Complex Parts &amp; BOM Graphs</li> <li>Supply Chain Models</li> <li>Graph Modeling Anti-Patterns</li> <li>Graph Algorithms</li> <li>openCypher / GSQL querying</li> <li>Data loading pipelines</li> <li>Best practices for graph schema design</li> </ul>"},{"location":"course-description/#topics-not-covered","title":"Topics Not Covered","text":"<p>*</p>"},{"location":"course-description/#learning-objectives-organized-by-blooms-taxonomy-2001-revision","title":"Learning Objectives (Organized by Bloom\u2019s Taxonomy \u2013 2001 Revision)","text":"<p>Below are the learning objectives grouped by Remember \u2192 Understand \u2192 Apply \u2192 Analyze \u2192 Evaluate \u2192 Create.</p>"},{"location":"course-description/#1-remember-factual-knowledge","title":"1. Remember (Factual Knowledge)","text":"<p>Students will be able to:</p> <ul> <li>Define key terms such as node, edge, property, label, schema-optional, and index-free adjacency.</li> <li>List the major categories of NoSQL systems.</li> <li>Identify the components of an LPG information model.</li> <li>Recall common graph query languages (openCypher, GSQL, Gremlin).</li> </ul>"},{"location":"course-description/#2-understand-conceptual-knowledge","title":"2. Understand (Conceptual Knowledge)","text":"<p>Students will be able to:</p> <ul> <li>Explain why traditional RDBMS systems struggle with highly connected data.</li> <li>Describe the tradeoffs among key-value, document, and graph stores.</li> <li>Summarize how graph queries locate patterns more naturally than SQL joins.</li> <li>Explain how concept dependency graphs represent knowledge structures.</li> <li>Compare various real-world graph models (social, supply chain, healthcare, etc.).</li> </ul>"},{"location":"course-description/#3-apply-procedural-knowledge","title":"3. Apply (Procedural Knowledge)","text":"<p>Students will be able to:</p> <ul> <li>Construct simple LPG models using nodes, edges, and properties.</li> <li>Write openCypher or GSQL queries to retrieve and aggregate graph data.</li> <li>Load data sets into a graph database using CSV or ETL pipelines.</li> <li>Implement graph traversal queries that compute multi-hop patterns.</li> <li>Use performance measurement tools to benchmark graph workloads.</li> </ul>"},{"location":"course-description/#4-analyze-breakdown-structure","title":"4. Analyze (Breakdown &amp; Structure)","text":"<p>Students will be able to:</p> <ul> <li>Differentiate between good and bad graph modeling choices.</li> <li>Decompose a domain into entities, relationships, and multi-edge structures.</li> <li>Examine performance logs to identify bottlenecks in graph queries.</li> <li>Analyze alternative graph schema representations for a given domain.</li> <li>Map complex business processes into multi-layered graph models (e.g., supply chain, IT dependency graph).</li> </ul>"},{"location":"course-description/#5-evaluate-judgment-critique","title":"5. Evaluate (Judgment &amp; Critique)","text":"<p>Students will be able to:</p> <ul> <li>Justify when a graph database is more appropriate than an RDBMS or document store.</li> <li>Evaluate competing graph schema designs for clarity, scalability, and performance.</li> <li>Critique query patterns for correctness, efficiency, and maintainability.</li> <li>Assess the appropriateness of chosen benchmarks and workload profiles.</li> <li>Defend the modeling decisions used in their capstone project.</li> </ul>"},{"location":"course-description/#6-create-synthesis-design","title":"6. Create (Synthesis &amp; Design)","text":"<p>Students will be able to:</p> <ul> <li>Design a complete LPG schema for a complex domain (healthcare, finance, supply chain, etc.).</li> <li>Develop multi-step graph queries supporting application requirements.</li> <li>Create an end-to-end graph system including ETL, schema, queries, and visualizations.</li> <li>Build and present a capstone graph application grounded in real-world data.</li> <li>Propose design improvements using graph algorithms or structural pattern refinements.</li> </ul> <p>If you'd like, I can also generate:</p> <ul> <li>A concept dependency graph for the course</li> <li>A full syllabus PDF</li> <li>A 14-week slide deck outline</li> <li>MicroSims that help teach specific topics (e.g., index-free adjacency, BFS traversal, fraud detection patterns)</li> </ul>"},{"location":"feedback/","title":"Feedback on Graph Data Modeling","text":"<p>You are welcome to connect with me on anytime on LinkedIn or submit any issues to GitHub Issue Log.  All pull-requests with fixes to errors or additions are always welcome.</p> <p>If you would like to fill out a short survey and give us ideas on how we can create better tools for intelligent textbooks in the future.</p>"},{"location":"glossary/","title":"Glossary of Terms","text":""},{"location":"glossary/#iso-definition","title":"ISO Definition","text":"<p>A term definition is considered to be consistent with ISO metadata registry guideline 11179 if it meets the following criteria:</p> <ol> <li>Precise</li> <li>Concise</li> <li>Distinct</li> <li>Non-circular</li> <li>Unencumbered with business rules</li> </ol>"},{"location":"glossary/#term","title":"Term","text":"<p>This is the definition of the term.</p>"},{"location":"how-we-built-this-site/","title":"How We Built This Site","text":"<p>This page describes how we built this website and some of  the rationale behind why we made various design choices.</p>"},{"location":"how-we-built-this-site/#python","title":"Python","text":"<p>MicroSims are about how we use generative AI to create animations and simulations.  The language of AI is Python.  So we wanted to create a site that could be easily understood by Python developers.</p>"},{"location":"how-we-built-this-site/#mkdocs-vs-docusaurus","title":"Mkdocs vs. Docusaurus","text":"<p>There are two main tools used by Python developers to write documentation: Mkdocs and Docusaurus.  Mkdocs is easier to use and more popular than Docusaurus. Docusaurus is also optimized for single-page applications. Mkdocs also has an extensive library of themes and plugins. None of us are experts in JavaScript or React. Based on our ChatGPT Analysis of the Tradeoffs we chose mkdocs for this site management.</p>"},{"location":"how-we-built-this-site/#github-and-github-pages","title":"GitHub and GitHub Pages","text":"<p>GitHub is a logical choice to store our  site source code and documentation.  GitHub also has a Custom GitHub Action that does auto-deployment if any files on the site change. We don't currently have this action enabled, but other teams can use this feature if they don't have the ability to do a local build with mkdocs.</p> <p>GitHub also has Issues,  Projects and releases that we can use to manage our bugs and tasks.</p> <p>The best practice for low-cost websites that have public-only content is GitHub Pages. Mkdocs has a command (<code>mkdocs gh-deploy</code>) that does deployment directly to GitHub Pages.  This was an easy choice to make.</p>"},{"location":"how-we-built-this-site/#github-clone","title":"GitHub Clone","text":"<p>If you would like to clone this repository, here are the commands:</p> <pre><code>mkdir projects\ncd projects\ngit clone https://github.com/dmccreary/microsims\n</code></pre>"},{"location":"how-we-built-this-site/#after-changes","title":"After Changes","text":"<p>After you make local changes you must do the following:</p> <pre><code># add the new files to a a local commit transaction\ngit add FILES\n# Execute the a local commit with a message about what and why you are doing the commit\ngit commit -m \"comment\"\n# Update the central GitHub repository\ngit push\n</code></pre>"},{"location":"how-we-built-this-site/#material-theme","title":"Material Theme","text":"<p>We had several options when picking a mkdocs theme:</p> <ol> <li>Mkdocs default</li> <li>Readthedocs</li> <li>Third-Party Themes See Ranking</li> </ol> <p>The Material Theme had 16K stars.  No other theme had over a few hundred. This was also an easy design decision.</p> <p>One key criterial was the social Open Graph tags so that when our users post a link to a simulation, the image of the simulation is included in the link.  Since Material supported this, we used the Material theme. You can see our ChatGPT Design Decision Analysis if you want to check our decision process.</p>"},{"location":"how-we-built-this-site/#enable-edit-icon","title":"Enable Edit Icon","text":"<p>To enable the Edit icon on all pages, you must add the edit_uri and the content.action.edit under the theme features area.</p> <pre><code>edit_uri: edit/master/docs/\n</code></pre> <pre><code>    theme:\n        features:\n            - content.action.edit\n</code></pre>"},{"location":"how-we-built-this-site/#conda-vs-venv","title":"Conda vs VENV","text":"<p>There are two choices for virtual environments.  We can use the native Python venv or use Conda.  venv is simle but is only designed for pure Python projects.  We imagine that this site could use JavaScript and other langauges in the future, so we picked Conda. There is nothing on this microsite that prevents you from using one or the other.  See the ChatGPT Analysis Here.</p> <p>Here is the conda script that we ran to create a new mkdocs environment that also supports the material social imaging libraries.</p> <pre><code>conda deactivate\nconda create -n mkdocs python=3\nconda activate mkdocs\npip install mkdocs \"mkdocs-material[imaging]\"\n</code></pre>"},{"location":"how-we-built-this-site/#mkdocs-commands","title":"Mkdocs Commands","text":"<p>There are three simple mkdoc commands we use.</p>"},{"location":"how-we-built-this-site/#local-build","title":"Local Build","text":"<pre><code>mkdocs build\n</code></pre> <p>This builds your website in a folder called <code>site</code>.  Use this to test that the mkdocs.yml site is working and does not have any errors.</p>"},{"location":"how-we-built-this-site/#run-a-local-server","title":"Run a Local Server","text":"<pre><code>mkdocs serve\n</code></pre> <p>This runs a server on <code>http://localhost:8000</code>. Use this to test the display formatting locally before you push your code up to the GitHub repo.</p> <pre><code>mkdoc gh-deploy\n</code></pre> <p>This pushes everything up to the GitHub Pages site. Note that it does not commit your code to GitHub.</p>"},{"location":"how-we-built-this-site/#mkdocs-material-social-tags","title":"Mkdocs Material Social Tags","text":"<p>We are using the Material Social tags.  This is a work in progress!</p> <p>Here is what we have learned.</p> <ol> <li>There are extensive image processing libraries that can't be installed with just pip.  You will need to run a tool like brew on the Mac to get the libraries installed.</li> <li>Even after <code>brew</code> installs the libraries, you have to get your environment to find the libraries.  The only way I could get that to work was to set up a local UNIX environment variable.</li> </ol> <p>Here is the brew command that I ran:</p> <pre><code>brew install cairo freetype libffi libjpeg libpng zlib\n</code></pre> <p>I then had to add the following to my ~/.zshrc file:</p> <pre><code>export DYLD_FALLBACK_LIBRARY_PATH=/opt/homebrew/lib\n</code></pre> <p>Note that I am running on a Mac with Apple silicon.  This means that the image libraries that brew downloads must be specific to the Mac Arm instruction set.</p>"},{"location":"how-we-built-this-site/#image-generation-and-compression","title":"Image Generation and Compression","text":"<p>I have used ChatGPT to create most of my images.  However, they are too large for most websites.  To compress them down I used  https://tinypng.com/ which is a free tool  for compressing png images without significant loss of quality.  The files created with ChatGPT are typically around 1-2 MB.  After  using the TinyPNG site the size is typically around 200-300KB.</p> <ul> <li>Cover images for blog post #4364</li> <li>Discussion on overriding the Social Card Image</li> </ul>"},{"location":"license/","title":"Creative Commons License","text":"<p>All content in this repository is governed by the following license agreement:</p>"},{"location":"license/#license-type","title":"License Type","text":"<p>Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0 DEED)</p>"},{"location":"license/#link-to-license-agreement","title":"Link to License Agreement","text":"<p>https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en</p>"},{"location":"license/#your-rights","title":"Your Rights","text":"<p>You are free to:</p> <ul> <li>Share \u2014 copy and redistribute the material in any medium or format</li> <li>Adapt \u2014 remix, transform, and build upon the material</li> </ul> <p>The licensor cannot revoke these freedoms as long as you follow the license terms.</p>"},{"location":"license/#restrictions","title":"Restrictions","text":"<ul> <li>Attribution \u2014 You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.</li> <li>NonCommercial \u2014 You may not use the material for commercial purposes.</li> <li>ShareAlike \u2014 If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.</li> <li>No additional restrictions \u2014 You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.</li> </ul> <p>Notices</p> <p>You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.</p> <p>No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.</p> <p>This deed highlights only some of the key features and terms of the actual license. It is not a license and has no legal value. You should carefully review all of the terms and conditions of the actual license before using the licensed material.</p>"},{"location":"references/","title":"Site References","text":"<ol> <li>mkdocs - https://www.mkdocs.org/ - this is our tool for building the website.  It converts Markdown into HTML in the <code>site</code> directory.</li> <li>mkdocs material theme - https://squidfunk.github.io/mkdocs-material/ - this is the theme for our site.  The theme adds the user interface elements that give our site the look and feel.  It also has the features such as social cards.</li> <li>GitHub Pages - https://pages.github.com/ - this is the free tool for hosting public websites created by mkdocs</li> <li>Markdown - https://www.mkdocs.org/user-guide/writing-your-docs/#writing-with-markdown - this is the format we use for text.  It allows us to have headers, lists, tables, links and images without learning HTML.</li> <li>Deploy Mkdocs GitHub Action - https://github.com/marketplace/actions/deploy-mkdocs - this is the tool we use to automatically build our site after edits are checked in with Git.</li> <li>Git Book - https://git-scm.com/book/en/v2 - a useful book on Git.  Just read the first two chapters to learn how to check in new code.</li> <li>Conda - https://conda.io/ - this is a command line tool that keeps our Python libraries organized for each project.</li> <li>VS Code - https://code.visualstudio.com/ - this is the integrated development environment we use to mange the files on our website.</li> <li>Markdown Paste - https://marketplace.visualstudio.com/items?itemName=telesoho.vscode-markdown-paste-image - this is the VS code extension we use to make sure we keep the markdown format generated by ChatGPT.</li> </ol>"}]}